{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gina-Kuo/NTHU_2025_DLIA_HW/blob/main/%E3%80%8CHW3_ipynb%E3%80%8D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Li0bVCTuxc6n"
      },
      "source": [
        "<div align=\"center\">\n",
        "\n",
        "#### Lab 3\n",
        "\n",
        "# National Tsing Hua University\n",
        "\n",
        "#### Spring 2025\n",
        "\n",
        "#### 11320IEEM 513600\n",
        "\n",
        "#### Deep Learning and Industrial Applications\n",
        "    \n",
        "## Lab 3: Anomaly Detection in Industrial Applications\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OlvflhYwCu8Q"
      },
      "source": [
        "### Introduction\n",
        "\n",
        "In today's industrial landscape, the ability to detect anomalies in manufacturing processes and products is critical for maintaining quality, efficiency, and safety. This lab focuses on leveraging deep learning techniques for anomaly detection in various industrial applications, using the MVTEC Anomaly Detection Dataset. By employing ImageNet-pretrained models available in torchvision, students will gain hands-on experience in classfying defects and irregularities across different types of industrial products.\n",
        "\n",
        "Throughout this lab, you'll be involved in the following key activities:\n",
        "- Explore and process the MVTec Anomaly Detection Dataset.\n",
        "- Apply ImageNet-pretrained models from [Torchvision](https://pytorch.org/vision/stable/models.html) to detect anomalies in industrial products.\n",
        "- Evaluate the performance of the models to understand their effectiveness in real-world industrial applications.\n",
        "\n",
        "### Objectives\n",
        "\n",
        "- Understand the principles of anomaly detection in the context of industrial applications.\n",
        "- Learn how to implement and utilize ImageNet-pretrained models for detecting anomalies.\n",
        "- Analyze and interpret the results of the anomaly detection models to assess their practicality in industrial settings.\n",
        "\n",
        "### Dataset\n",
        "\n",
        "The MVTec AD Dataset is a comprehensive collection of high-resolution images across different categories of industrial products, such as bottles, cables, and metal nuts, each with various types of defects. This dataset is pivotal for developing and benchmarking anomaly detection algorithms. You can download our lab's dataset [here](https://drive.google.com/file/d/19600hUOpx0hl78TdpdH0oyy-gGTk_F_o/view?usp=share_link). You can drop downloaded data and drop to colab, or you can put into yor google drive.\n",
        "\n",
        "### References\n",
        "- [MVTec AD Dataset](https://www.kaggle.com/datasets/ipythonx/mvtec-ad/data) for the dataset used in this lab.\n",
        "- [Torchvision Models](https://pytorch.org/vision/stable/models.html) for accessing ImageNet-pretrained models to be used in anomaly detection tasks.\n",
        "- [State-of-the-Art Anomaly Detection on MVTec AD](https://paperswithcode.com/sota/anomaly-detection-on-mvtec-ad) for insights into the latest benchmarks and methodologies in anomaly detection applied to the MVTec AD dataset.\n",
        "- [CVPR 2019: MVTec AD — A Comprehensive Real-World Dataset for Unsupervised Anomaly Detection] for the original paper of MVTec AD dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GuiEw1L0Cu8Q"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from tqdm.auto import tqdm\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3GiOZBRJCu8S"
      },
      "outputs": [],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Set the category to extract (e.g., bottle, cable, etc.)\n",
        "category = \"bottle\"\n",
        "image_path = f\"/content/drive/MyDrive/Colab Notebooks/{category}\"\n",
        "\n",
        "# Define root paths\n",
        "drive_root = \"/content/drive/MyDrive/Colab Notebooks/bottle\"\n",
        "train_dir = os.path.join(drive_root, \"train\")\n",
        "test_dir = os.path.join(drive_root, \"test\")\n",
        "\n",
        "# Get train and test image paths\n",
        "train_images = glob.glob(f\"{train_dir}/good/*.png\")\n",
        "test_images = glob.glob(f\"{test_dir}/**/*.png\", recursive=True)\n",
        "\n",
        "# Count classes (excluding 'good')\n",
        "defect_classes = [d for d in os.listdir(test_dir) if d != 'good']\n",
        "num_defect_classes = len(defect_classes)\n",
        "\n",
        "# Example image to get dimensions\n",
        "sample_img = cv2.imread(train_images[0])\n",
        "height, width, channels = sample_img.shape\n",
        "\n",
        "# Output\n",
        "print(\"Dataset Summary for 'bottle':\")\n",
        "print(f\"Number of defect classes: {num_defect_classes}\")\n",
        "print(f\"Types of defect classes: {defect_classes}\")\n",
        "print(f\"Total images used: {len(train_images) + len(test_images)}\")\n",
        "print(f\"  - Training images (only 'good'): {len(train_images)}\")\n",
        "print(f\"  - Test images (good + defective): {len(test_images)}\")\n",
        "print(f\"Image dimensions: {width} x {height} x {channels}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_paths = glob.glob(\"/content/drive/MyDrive/Colab Notebooks/bottle/**/*/*.png\", recursive=True)"
      ],
      "metadata": {
        "id": "K_G_N5AFflrg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ii8LH8s4Cu8S"
      },
      "outputs": [],
      "source": [
        "all_data = []\n",
        "\n",
        "for img in tqdm(file_paths):\n",
        "    img = cv2.imread(img)\n",
        "    img = img[..., ::-1]\n",
        "    all_data.append(img)\n",
        "\n",
        "all_data = np.stack(all_data)\n",
        "print(all_data.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Define your test directory\n",
        "test_dir = \"/content/drive/MyDrive/Colab Notebooks/bottle/test\"\n",
        "\n",
        "# Get class names from the test folder (e.g., good, broken_large, etc.)\n",
        "classes = sorted([d for d in os.listdir(test_dir) if os.path.isdir(os.path.join(test_dir, d))])\n",
        "print(f'Classes: {classes}')\n",
        "\n",
        "# Show 2 images from each class\n",
        "fig, axs = plt.subplots(len(classes), 2, figsize=(6, 4 * len(classes)))\n",
        "\n",
        "for i, class_name in enumerate(classes):\n",
        "    class_folder = os.path.join(test_dir, class_name)\n",
        "    images = sorted(glob.glob(f\"{class_folder}/*.png\"))[:2]  # get first 2 images\n",
        "\n",
        "    for j, img_path in enumerate(images):\n",
        "        img = cv2.imread(img_path)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        axs[i, j].imshow(img)\n",
        "        axs[i, j].axis('off')\n",
        "        axs[i, j].set_title(f'{class_name}')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "y8B5vMCLf5yf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-1PsC--M7pT"
      },
      "source": [
        "## A. Data Loading and Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nGFI8GMpCu8S"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "import torch\n",
        "\n",
        "# 假設 all_data 是 shape=(355, H, W, C)，前 60 張為 good\n",
        "num_good = 60\n",
        "num_defect = len(all_data) - num_good\n",
        "all_labels = np.concatenate([np.zeros(num_good), np.ones(num_defect)]).astype(int)  # 0: good, 1: defect\n",
        "\n",
        "# ✅ 分層切分資料\n",
        "x_train, x_val, y_train, y_val = train_test_split(\n",
        "    all_data, all_labels, test_size=0.2, stratify=all_labels, random_state=42\n",
        ")\n",
        "\n",
        "# ✅ NHWC ➜ NCHW\n",
        "x_train = np.transpose(x_train, (0, 3, 1, 2))\n",
        "x_val = np.transpose(x_val, (0, 3, 1, 2))\n",
        "\n",
        "# ✅ 自訂 Dataset 類別\n",
        "class MyDataset(Dataset):\n",
        "    def __init__(self, x, y, transform=None):\n",
        "        self.x = x\n",
        "        self.y = torch.tensor(y, dtype=torch.long)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = Image.fromarray(np.transpose(self.x[idx], (1, 2, 0)).astype(np.uint8))\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, self.y[idx]\n",
        "\n",
        "# ✅ 印出分布確認\n",
        "print(f\"x_train: {x_train.shape}, y_train: {y_train.shape}\")\n",
        "print(f\"x_val:   {x_val.shape}, y_val:   {y_val.shape}\")\n",
        "print(\"Train label dist:\", np.bincount(y_train))\n",
        "print(\"Val label dist:  \", np.bincount(y_val))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h-CnfsmbCu8T"
      },
      "outputs": [],
      "source": [
        "for experiment_id in range(1, 5):\n",
        "    print(f\"\\n🔁 Running Experiment {experiment_id}...\")\n",
        "\n",
        "    # === 超參數設定 ===\n",
        "    if experiment_id == 1:\n",
        "        input_size = 128; batch_size = 32; lr = 1e-3; epochs = 30; model_type = \"resnet18\"\n",
        "    elif experiment_id == 2:\n",
        "        input_size = 128; batch_size = 32; lr = 1e-3; epochs = 30; model_type = \"resnet50\"\n",
        "    elif experiment_id == 3:\n",
        "        input_size = 128; batch_size = 16; lr = 1e-3; epochs = 50; model_type = \"resnet18\"\n",
        "    elif experiment_id == 4:\n",
        "        input_size = 128; batch_size = 16; lr = 1e-4; epochs = 50; model_type = \"resnet18\"\n",
        "\n",
        "    # === transforms 每次重建（依據 input_size）===\n",
        "    train_transforms = transforms.Compose([\n",
        "        transforms.Resize((input_size, input_size)),\n",
        "        transforms.AutoAugment(),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "    val_transforms = transforms.Compose([\n",
        "        transforms.Resize((input_size, input_size)),\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "\n",
        "    # === 每次都重建 Dataset & DataLoader ===\n",
        "    train_dataset = MyDataset(x_train, y_train, transform=train_transforms)\n",
        "    val_dataset = MyDataset(x_val, y_val, transform=val_transforms)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,\n",
        "                              num_workers=2, pin_memory=True, persistent_workers=True)\n",
        "    val_loader   = DataLoader(val_dataset, batch_size=batch_size, shuffle=False,\n",
        "                              num_workers=1, pin_memory=True, persistent_workers=True)\n",
        "\n",
        "    # ✅ 接下來繼續 model 初始化、訓練等流程...\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oaLGtT28xc6s"
      },
      "source": [
        "## B. Defining Neural Networks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oDX8iDKJCu8U"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "from torchvision import models\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "results = {}\n",
        "\n",
        "# --- 跑四個實驗 ---\n",
        "for experiment_id in range(1, 5):\n",
        "    print(f\"\\n\\n Running Experiment {experiment_id}...\")\n",
        "\n",
        "    # === 超參數設定 ===\n",
        "    if experiment_id == 1:\n",
        "        input_size = 128; batch_size = 32; lr = 1e-3; epochs = 30\n",
        "    elif experiment_id == 2:\n",
        "        input_size = 128; batch_size = 32; lr = 1e-3; epochs = 30\n",
        "    elif experiment_id == 3:\n",
        "        input_size = 128; batch_size = 16; lr = 1e-3; epochs = 50\n",
        "    elif experiment_id == 4:\n",
        "        input_size = 128; batch_size = 16; lr = 1e-4; epochs = 50\n",
        "\n",
        "    train_transforms = transforms.Compose([\n",
        "        transforms.Resize((input_size, input_size)),\n",
        "        transforms.AutoAugment(),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "    val_transforms = transforms.Compose([\n",
        "        transforms.Resize((input_size, input_size)),\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "\n",
        "    train_dataset = MyDataset(x_train, y_train, transform=train_transforms)\n",
        "    val_dataset = MyDataset(x_val, y_val, transform=val_transforms)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    # === 模型架構 ===\n",
        "    if experiment_id == 2:\n",
        "        model = models.resnet50(weights='IMAGENET1K_V1')\n",
        "    else:\n",
        "        model = models.resnet18(weights='IMAGENET1K_V1')\n",
        "\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "    for name, param in model.named_parameters():\n",
        "        if \"layer4\" in name:\n",
        "            param.requires_grad = True\n",
        "\n",
        "    model.fc = nn.Linear(model.fc.in_features, 2)\n",
        "    model = model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvLTU-IfZLqn"
      },
      "source": [
        "## C. Training the Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "45ol4lpVxc6t"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "# ✅ 2. Dataset 定義（如果還沒定義）\n",
        "class MyDataset(Dataset):\n",
        "    def __init__(self, x, y, transform=None):\n",
        "        self.x = x\n",
        "        self.y = torch.from_numpy(y).long()\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        new_x = np.transpose(self.x[idx], (1, 2, 0)).astype(np.uint8)\n",
        "        img = Image.fromarray(new_x)\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        return img, self.y[idx]\n",
        "\n",
        "# ✅ 3. 訓練與儲存結果（必要時重新執行）\n",
        "results = {}\n",
        "label_counter = Counter(y_train)\n",
        "class_weights = [1.0 / label_counter[0], 1.0 / label_counter[1]]\n",
        "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
        "\n",
        "for experiment_id in range(1, 5):\n",
        "    print(f\"\\n🔁 Running Experiment {experiment_id}...\")\n",
        "\n",
        "    # === 超參數設定 ===\n",
        "    if experiment_id == 1:\n",
        "        input_size = 128; batch_size = 32; lr = 1e-3; epochs = 30\n",
        "    elif experiment_id == 2:\n",
        "        input_size = 128; batch_size = 32; lr = 1e-3; epochs = 30\n",
        "    elif experiment_id == 3:\n",
        "        input_size = 128; batch_size = 16; lr = 1e-3; epochs = 50\n",
        "    elif experiment_id == 4:\n",
        "        input_size = 128; batch_size = 16; lr = 1e-4; epochs = 50\n",
        "\n",
        "    # === transforms ===\n",
        "    train_transforms = transforms.Compose([\n",
        "        transforms.Resize((input_size, input_size)),\n",
        "        transforms.AutoAugment(),\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "    val_transforms = transforms.Compose([\n",
        "        transforms.Resize((input_size, input_size)),\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "\n",
        "    # === Dataloader ===\n",
        "    train_dataset = MyDataset(x_train, y_train, transform=train_transforms)\n",
        "    val_dataset = MyDataset(x_val, y_val, transform=val_transforms)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    # === 模型定義 ===\n",
        "    if experiment_id == 2:\n",
        "        model = models.resnet50(weights='IMAGENET1K_V1')\n",
        "    else:\n",
        "        model = models.resnet18(weights='IMAGENET1K_V1')\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "    for name, param in model.named_parameters():\n",
        "        if \"layer4\" in name:\n",
        "            param.requires_grad = True\n",
        "    model.fc = nn.Linear(model.fc.in_features, 2)\n",
        "    model = model.to(device)\n",
        "\n",
        "    # === Loss, Optimizer, Scheduler ===\n",
        "    criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
        "    optimizer = Adam(model.parameters(), lr=lr)\n",
        "    scheduler = CosineAnnealingLR(optimizer, T_max=len(train_loader)*epochs, eta_min=0)\n",
        "\n",
        "    best_val_acc = -1\n",
        "    train_losses, val_losses = [], []\n",
        "    train_accuracies, val_accuracies = [], []\n",
        "\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "        model.train()\n",
        "        total_loss, correct, total = 0.0, 0, 0\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "            preds = outputs.argmax(dim=1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "        train_losses.append(total_loss / len(train_loader))\n",
        "        train_accuracies.append(100. * correct / total)\n",
        "\n",
        "        model.eval()\n",
        "        val_loss, val_correct, val_total = 0.0, 0, 0\n",
        "        with torch.no_grad():\n",
        "            for images, labels in val_loader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "                val_loss += loss.item()\n",
        "                val_correct += (outputs.argmax(1) == labels).sum().item()\n",
        "                val_total += labels.size(0)\n",
        "        val_losses.append(val_loss / len(val_loader))\n",
        "        val_acc = 100. * val_correct / val_total\n",
        "        val_accuracies.append(val_acc)\n",
        "        scheduler.step()\n",
        "\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            torch.save(model.state_dict(), f\"model_exp{experiment_id}.pth\")\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs} - Train Acc: {train_accuracies[-1]:.2f}% - Val Acc: {val_acc:.2f}%\")\n",
        "\n",
        "    results[experiment_id] = {\n",
        "        \"train_acc\": train_accuracies,\n",
        "        \"val_acc\": val_accuracies,\n",
        "        \"train_loss\": train_losses,\n",
        "        \"val_loss\": val_losses,\n",
        "    }\n",
        "\n",
        "# ✅ 儲存 results 結果\n",
        "with open(\"results.pkl\", \"wb\") as f:\n",
        "    pickle.dump(results, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjmYxAJnxc6t"
      },
      "source": [
        "### Visualizing model performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pHpS0Q7vxc6t"
      },
      "outputs": [],
      "source": [
        "# ✅ 4. 載入結果 & 畫圖（可以單獨執行這段）\n",
        "with open(\"results.pkl\", \"rb\") as f:\n",
        "    results = pickle.load(f)\n",
        "\n",
        "for i in range(1, 5):\n",
        "    if i not in results:\n",
        "        print(f\"❌ Experiment {i} 的結果不存在\")\n",
        "        continue\n",
        "    train_acc = results[i][\"train_acc\"]\n",
        "    val_acc = results[i][\"val_acc\"]\n",
        "    train_loss = results[i][\"train_loss\"]\n",
        "    val_loss = results[i][\"val_loss\"]\n",
        "\n",
        "    plt.figure(figsize=(12, 4))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(train_acc, label=\"Train Accuracy\")\n",
        "    plt.plot(val_acc, label=\"Validation Accuracy\")\n",
        "    plt.title(f\"Experiment {i} - Accuracy\")\n",
        "    plt.xlabel(\"Epoch\"); plt.ylabel(\"Accuracy (%)\")\n",
        "    plt.grid(True); plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(train_loss, label=\"Train Loss\")\n",
        "    plt.plot(val_loss, label=\"Validation Loss\")\n",
        "    plt.title(f\"Experiment {i} - Loss\")\n",
        "    plt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\")\n",
        "    plt.grid(True); plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVDWBwv6Cu8V"
      },
      "source": [
        "## D. Evaluating Your Trained Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uEztHBDjCu8V"
      },
      "source": [
        "### Load Trained Model and Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2DA1qHXpCu8V"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "for i in range(1, 5):\n",
        "    print(f\"\\n🔍 Evaluating Experiment {i}...\")\n",
        "\n",
        "    # ✅ 正確選擇模型架構\n",
        "    if i == 2:\n",
        "        model = models.resnet50(weights='IMAGENET1K_V1')\n",
        "        num_ftrs = model.fc.in_features  # ResNet50: 2048\n",
        "    else:\n",
        "        model = models.resnet18(weights='IMAGENET1K_V1')\n",
        "        num_ftrs = model.fc.in_features  # ResNet18: 512\n",
        "\n",
        "    model.fc = nn.Linear(num_ftrs, 2)\n",
        "    model.load_state_dict(torch.load(f\"model_exp{i}.pth\", map_location=device))\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    # === 評估準確率 ===\n",
        "    test_correct = 0\n",
        "    test_total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images, labels = images.to(device), labels.to(device).long()\n",
        "            outputs = model(images)\n",
        "            preds = outputs.argmax(-1)\n",
        "            test_correct += (preds == labels).sum().item()\n",
        "            test_total += labels.size(0)\n",
        "\n",
        "    test_acc = 100. * test_correct / test_total\n",
        "    print(f\"✅ Final Test Accuracy for Experiment {i}: {test_acc:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jG6DuAgcEgxj"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}